{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network with 2D Data (2-dimensional)\n",
    "- Neural Network with 4 layers\n",
    "- 2D data f(x,y) -> R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "from visdom import Visdom\n",
    "viz = Visdom()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/NLPApps/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/envs/NLPApps/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  \"\"\"\n",
      "/anaconda3/envs/NLPApps/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  \n",
      "/anaconda3/envs/NLPApps/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "num_data=1000\n",
    "num_epoch=10000\n",
    "\n",
    "x = init.uniform(torch.Tensor(num_data,1),-10,10)\n",
    "y = init.uniform(torch.Tensor(num_data,1),-10,10)\n",
    "z = x**2 + y**2\n",
    "\n",
    "x_noise = x + init.normal(torch.FloatTensor(num_data,1),std=0.5)\n",
    "y_noise = y + init.normal(torch.FloatTensor(num_data,1),std=0.5)\n",
    "z_noise = x_noise**2 + y_noise**2\n",
    "\n",
    "data_noise = torch.cat([x,y,z_noise],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualization\n",
    "\n",
    "win_1=viz.scatter(\n",
    "        X=data_noise,\n",
    "        opts=dict(\n",
    "            markersize=5,\n",
    "            markercolor=np.ndarray(shape=[num_data,3],dtype=float,buffer=[51,153,255]*np.ones(shape=[num_data,3]))\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(2,20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20,10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10,5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5,5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5,1),\n",
    "        )\n",
    "\n",
    "loss_func = nn.L1Loss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(65.7104, grad_fn=<L1LossBackward>)\n",
      "tensor(65.2817, grad_fn=<L1LossBackward>)\n",
      "tensor(64.3548, grad_fn=<L1LossBackward>)\n",
      "tensor(59.0717, grad_fn=<L1LossBackward>)\n",
      "tensor(17.8562, grad_fn=<L1LossBackward>)\n",
      "tensor(16.8119, grad_fn=<L1LossBackward>)\n",
      "tensor(15.9797, grad_fn=<L1LossBackward>)\n",
      "tensor(15.1852, grad_fn=<L1LossBackward>)\n",
      "tensor(14.3976, grad_fn=<L1LossBackward>)\n",
      "tensor(13.5923, grad_fn=<L1LossBackward>)\n"
     ]
    }
   ],
   "source": [
    "input_data = torch.cat([x,y],1)\n",
    "label = z_noise\n",
    "loss_arr =[]\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input_data)\n",
    "    loss = loss_func(output,label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_arr.append(loss.item())\n",
    "    \n",
    "    if i % 100 == 0 and i <1000:\n",
    "        print(loss)\n",
    "        data = torch.cat([input_data.cpu(),output.cpu().data],1)\n",
    "\n",
    "        win_2 =viz.scatter(\n",
    "                X=data,\n",
    "                opts=dict(\n",
    "                markersize=5,\n",
    "                markercolor=np.ndarray(shape=[num_data,3],dtype=float,buffer=128*np.ones(shape=[num_data,3]))\n",
    "            )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.6850, -0.0502],\n",
      "        [-0.0602,  0.6183],\n",
      "        [-0.5313, -0.1488],\n",
      "        [ 0.2152, -0.4306],\n",
      "        [-0.3224,  0.5263],\n",
      "        [-0.5309, -0.2665],\n",
      "        [-0.0100,  0.5336],\n",
      "        [-0.5840,  0.3759],\n",
      "        [ 0.0469, -0.3801],\n",
      "        [ 0.1406, -0.0129],\n",
      "        [ 0.5754,  0.1552],\n",
      "        [-0.6669, -0.1991],\n",
      "        [ 0.3849,  0.2107],\n",
      "        [ 0.2044, -0.2215],\n",
      "        [ 0.6126, -0.4046],\n",
      "        [-0.1895,  0.0895],\n",
      "        [ 0.0031, -0.6413],\n",
      "        [ 0.5738,  0.2672],\n",
      "        [ 0.0506, -0.3940],\n",
      "        [-0.3437, -0.5539]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4888, -1.0308,  0.7251, -0.5987, -0.5087, -0.9675, -0.1662, -0.4251,\n",
      "        -0.1087,  0.0203, -0.1181,  0.3905, -0.9619,  0.9565, -0.4687, -1.1564,\n",
      "        -1.0662,  0.4190,  0.1819, -0.4831], requires_grad=True), Parameter containing:\n",
      "tensor([[ 1.4889e-01, -1.1155e-01, -1.6971e-01, -8.6068e-02, -1.5838e-02,\n",
      "         -2.3946e-02,  1.7094e-01, -8.2129e-02,  7.3365e-02,  1.0633e-01,\n",
      "         -2.1965e-01,  1.9926e-01, -4.0231e-02, -1.3578e-01,  1.2571e-01,\n",
      "         -2.0266e-01,  1.6148e-01,  6.4892e-02, -1.9794e-01,  1.1698e-01],\n",
      "        [-5.4253e-02, -8.3769e-02, -1.1826e-01, -1.8230e-01,  8.4314e-02,\n",
      "         -1.5059e-01, -1.6211e-01,  1.2246e-01,  1.6046e-01, -9.5762e-02,\n",
      "         -2.2292e-01, -2.3933e-02, -9.5710e-02,  8.4106e-02,  1.0983e-01,\n",
      "         -1.2158e-01,  6.1846e-02, -1.7340e-01, -5.0437e-02,  8.3566e-02],\n",
      "        [-1.7291e-02, -2.7549e-01, -2.3538e-01, -4.8257e-02,  4.6909e-02,\n",
      "          1.7114e-01,  1.4544e-01,  9.4686e-02, -2.2952e-01,  1.2778e-01,\n",
      "          9.2291e-02, -2.3026e-02, -1.4666e-01, -1.8399e-01,  6.5691e-02,\n",
      "         -2.0687e-01,  1.1292e-01,  5.9465e-02,  7.4160e-02, -1.6486e-01],\n",
      "        [-4.7962e-02,  7.2410e-03,  1.0091e-01, -4.3782e-02,  3.1189e-01,\n",
      "          6.8901e-02, -7.6564e-02,  2.4175e-02, -1.9893e-01,  1.0230e-02,\n",
      "         -2.2865e-01,  2.3163e-01, -2.1464e-01, -1.4559e-01,  1.3220e-01,\n",
      "         -1.4087e-01,  1.3774e-01, -2.5857e-02, -1.5756e-01, -8.0966e-02],\n",
      "        [-2.5894e-02, -1.5745e-01, -1.9194e-01, -2.0014e-01,  3.6449e-02,\n",
      "          1.1481e-01,  3.4266e-02, -2.1382e-01,  4.2756e-02, -1.9393e-01,\n",
      "          1.1231e-01,  1.0242e-02, -1.7611e-01,  1.0944e-01, -1.7654e-02,\n",
      "         -1.7495e-01, -2.1738e-01, -2.9918e-02, -1.6334e-01, -2.1651e-01],\n",
      "        [ 1.6636e-01,  1.7720e-01,  1.0009e-01,  3.4878e-01,  3.5001e-01,\n",
      "          2.8880e-01,  1.2721e-01,  2.4050e-01,  1.3971e-01,  7.2098e-02,\n",
      "         -1.2359e-01,  4.0282e-01,  6.8714e-01, -2.9372e-01,  3.1492e-01,\n",
      "          5.7104e-01,  5.8120e-01, -3.3310e-01,  1.6676e-01,  2.0012e-01],\n",
      "        [ 4.1641e-01,  5.2690e-01, -3.6864e-01,  1.2357e-01,  2.0754e-01,\n",
      "          5.9341e-01,  2.9053e-01,  2.6454e-02, -2.2935e-02,  1.0373e-01,\n",
      "          4.6656e-02, -1.9442e-01,  3.1096e-01, -3.5194e-01,  3.8482e-01,\n",
      "          4.2007e-01,  2.7193e-01,  4.5967e-01, -1.1779e-01,  2.4638e-01],\n",
      "        [ 2.9753e-01,  8.0613e-02, -3.3192e-02,  5.6572e-02,  1.4092e-01,\n",
      "          2.6549e-01, -7.0413e-02,  2.6446e-01,  1.6435e-01, -1.2925e-01,\n",
      "          1.9507e-01, -1.7673e-01,  3.0506e-01, -4.2177e-01,  1.3950e-01,\n",
      "          3.3100e-01,  8.4033e-02, -2.4319e-01, -7.5169e-02,  2.2410e-01],\n",
      "        [ 3.7452e-01,  4.1349e-01, -2.8208e-01,  1.0730e-01, -1.0936e-01,\n",
      "          5.8586e-01, -2.0035e-03,  1.9071e-01, -1.2956e-04,  7.8599e-02,\n",
      "          7.5478e-02, -3.2026e-03,  1.5547e-01, -3.2716e-01,  4.8107e-02,\n",
      "          4.3779e-01,  2.7893e-01, -6.8370e-02, -2.0383e-01,  2.8877e-01],\n",
      "        [-2.1360e-01, -1.7487e-01,  1.3207e-01, -1.9994e-01,  1.4764e-01,\n",
      "         -1.0977e-01,  1.8851e-01, -8.5563e-02, -1.6154e-01, -4.7761e-02,\n",
      "          8.4696e-02, -1.1438e-01, -1.2789e-02, -1.0745e-01, -2.0768e-01,\n",
      "          8.8541e-02,  1.0871e-01, -2.0628e-01,  7.9616e-02, -1.3233e-01]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.3465, -0.1907, -0.1866,  0.0490, -0.1020, -0.9633, -0.8486, -1.1435,\n",
      "        -1.3174, -0.0223], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.3101,  0.0886,  0.2336,  0.2394,  0.0635,  0.1035,  0.0745,  0.3874,\n",
      "          0.0667,  0.1560],\n",
      "        [ 0.1973, -0.0074,  0.1252,  0.3826,  0.0358,  0.8926,  1.0405,  0.9652,\n",
      "          0.8909, -0.2443],\n",
      "        [ 0.1335,  0.1467, -0.2293,  0.0726, -0.2297, -0.0933, -0.1243, -0.0845,\n",
      "         -0.3013, -0.1705],\n",
      "        [ 0.0189, -0.2594, -0.0413,  0.2676,  0.1956, -0.1477, -0.2749,  0.2350,\n",
      "          0.2115, -0.0901],\n",
      "        [ 0.2514, -0.1142, -0.2890, -0.0958, -0.3095,  0.9055,  0.7897,  0.7240,\n",
      "          1.1040,  0.0943]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0600,  0.1657, -0.2799, -0.1571, -0.4197], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.2588, -0.2085,  0.4069,  0.1290, -0.3517],\n",
      "        [ 0.4527,  0.6542, -0.0778,  0.2590,  0.9698],\n",
      "        [ 0.1057,  1.3901, -0.0260, -0.1421,  1.0220],\n",
      "        [ 0.0666,  1.1376, -0.2540, -0.2207,  1.2169],\n",
      "        [-0.0458,  0.0655,  0.3293,  0.1478, -0.0640]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2014,  0.1511,  0.5341,  0.4851, -0.1495], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.2743,  1.1525,  1.7831,  1.6653, -0.3657]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0657], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "param_list = list(model.parameters())\n",
    "print(param_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Trained Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.cat([input_data.cpu(),output.cpu().data],1)\n",
    "\n",
    "win_2 =viz.scatter(\n",
    "        X=data,\n",
    "        opts=dict(\n",
    "        markersize=5,\n",
    "        markercolor=np.ndarray(shape=[num_data,3],dtype=float,buffer=128*np.ones(shape=[num_data,3]))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Loss Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.reshape([i for i in range(num_epoch)],newshape=[num_epoch,1])\n",
    "loss_data = np.reshape(loss_arr,newshape=[num_epoch,1])\n",
    "\n",
    "win3=viz.line(\n",
    "    X = x,\n",
    "    Y = loss_data,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
