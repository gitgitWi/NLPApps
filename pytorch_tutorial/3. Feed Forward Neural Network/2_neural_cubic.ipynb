{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network with Cubic Data (multi-dimensional)\n",
    "- y = x^3 -3x^2 -9x -1\n",
    "- 5 hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "from visdom import Visdom\n",
    "viz = Visdom()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/NLPApps/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/envs/NLPApps/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "num_data = 1000\n",
    "num_epoch = 5000\n",
    "\n",
    "x = init.uniform(torch.Tensor(num_data,1),-10,10)\n",
    "y = (x**3) - 3*(x**2) - 9*x - 1\n",
    "\n",
    "noise = init.normal(torch.FloatTensor(num_data,1),std=3)\n",
    "\n",
    "y_noise = y + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize data\n",
    "\n",
    "input_data = torch.cat([x,y_noise],1)\n",
    "\n",
    "win=viz.scatter(\n",
    "    X = input_data,\n",
    "    opts=dict(\n",
    "        xtickmin=-10,\n",
    "        xtickmax=10,\n",
    "        xtickstep=1,\n",
    "        ytickmin=0,\n",
    "        ytickmax=500,\n",
    "        ytickstep=1,\n",
    "        markersymbol='dot',\n",
    "        markercolor=np.random.randint(0, 255, num_data),\n",
    "        markersize=5,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize data\n",
    "\n",
    "input_data = torch.cat([x,y_noise],1)\n",
    "\n",
    "win=viz.scatter(\n",
    "    X = torch.cat([x,y],1),\n",
    "    opts=dict(\n",
    "        xtickmin=-10,\n",
    "        xtickmax=10,\n",
    "        xtickstep=1,\n",
    "        ytickmin=0,\n",
    "        ytickmax=500,\n",
    "        ytickstep=1,\n",
    "        markersymbol='dot',\n",
    "        markercolor=np.random.randint(0, 255, num_data),\n",
    "        markersize=5,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully connected model with 5 hidden layer\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(1,20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20,10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10,5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5,1),\n",
    "        )\n",
    "\n",
    "loss_func = nn.L1Loss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(210.9340, grad_fn=<L1LossBackward>)\n",
      "tensor(210.8821, grad_fn=<L1LossBackward>)\n",
      "tensor(210.8308, grad_fn=<L1LossBackward>)\n",
      "tensor(210.8036, grad_fn=<L1LossBackward>)\n",
      "tensor(210.7703, grad_fn=<L1LossBackward>)\n",
      "tensor(210.7277, grad_fn=<L1LossBackward>)\n",
      "tensor(210.6704, grad_fn=<L1LossBackward>)\n",
      "tensor(210.5876, grad_fn=<L1LossBackward>)\n",
      "tensor(210.4600, grad_fn=<L1LossBackward>)\n",
      "tensor(210.2420, grad_fn=<L1LossBackward>)\n",
      "tensor(209.8103, grad_fn=<L1LossBackward>)\n",
      "tensor(208.7260, grad_fn=<L1LossBackward>)\n",
      "tensor(204.5924, grad_fn=<L1LossBackward>)\n",
      "tensor(166.6677, grad_fn=<L1LossBackward>)\n",
      "tensor(133.7842, grad_fn=<L1LossBackward>)\n",
      "tensor(129.7256, grad_fn=<L1LossBackward>)\n",
      "tensor(123.7340, grad_fn=<L1LossBackward>)\n",
      "tensor(115.6698, grad_fn=<L1LossBackward>)\n",
      "tensor(108.3235, grad_fn=<L1LossBackward>)\n",
      "tensor(99.2278, grad_fn=<L1LossBackward>)\n",
      "tensor(84.6065, grad_fn=<L1LossBackward>)\n",
      "tensor(64.0752, grad_fn=<L1LossBackward>)\n",
      "tensor(58.7412, grad_fn=<L1LossBackward>)\n",
      "tensor(54.6009, grad_fn=<L1LossBackward>)\n",
      "tensor(37.7647, grad_fn=<L1LossBackward>)\n",
      "tensor(39.0460, grad_fn=<L1LossBackward>)\n",
      "tensor(35.1779, grad_fn=<L1LossBackward>)\n",
      "tensor(54.3058, grad_fn=<L1LossBackward>)\n",
      "tensor(36.7735, grad_fn=<L1LossBackward>)\n",
      "tensor(43.4536, grad_fn=<L1LossBackward>)\n",
      "tensor(31.3307, grad_fn=<L1LossBackward>)\n",
      "tensor(22.7198, grad_fn=<L1LossBackward>)\n",
      "tensor(25.9747, grad_fn=<L1LossBackward>)\n",
      "tensor(33.1543, grad_fn=<L1LossBackward>)\n",
      "tensor(42.0036, grad_fn=<L1LossBackward>)\n",
      "tensor(36.2529, grad_fn=<L1LossBackward>)\n",
      "tensor(33.4738, grad_fn=<L1LossBackward>)\n",
      "tensor(21.8014, grad_fn=<L1LossBackward>)\n",
      "tensor(38.1863, grad_fn=<L1LossBackward>)\n",
      "tensor(23.3798, grad_fn=<L1LossBackward>)\n",
      "tensor(38.5462, grad_fn=<L1LossBackward>)\n",
      "tensor(31.7237, grad_fn=<L1LossBackward>)\n",
      "tensor(30.2160, grad_fn=<L1LossBackward>)\n",
      "tensor(29.5481, grad_fn=<L1LossBackward>)\n",
      "tensor(26.2210, grad_fn=<L1LossBackward>)\n",
      "tensor(20.7712, grad_fn=<L1LossBackward>)\n",
      "tensor(19.0126, grad_fn=<L1LossBackward>)\n",
      "tensor(16.6167, grad_fn=<L1LossBackward>)\n",
      "tensor(16.3853, grad_fn=<L1LossBackward>)\n",
      "tensor(31.7720, grad_fn=<L1LossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss_arr =[]\n",
    "label = y_noise\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    output = model(x)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = loss_func(output,label)\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 100 ==0:\n",
    "        print(loss)\n",
    "        \n",
    "    #loss_arr.append(loss.cpu().data.numpy()[0])\n",
    "    loss_arr.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.5488],\n",
      "        [-0.9242],\n",
      "        [-0.5968],\n",
      "        [ 0.7953],\n",
      "        [ 0.6045],\n",
      "        [-0.2598],\n",
      "        [-0.5008],\n",
      "        [-0.6928],\n",
      "        [ 0.4209],\n",
      "        [-0.1503],\n",
      "        [-0.5346],\n",
      "        [-1.4426],\n",
      "        [ 0.6893],\n",
      "        [-0.4991],\n",
      "        [ 0.4590],\n",
      "        [ 0.3660],\n",
      "        [-0.6303],\n",
      "        [-0.0624],\n",
      "        [ 0.4534],\n",
      "        [ 0.4127]], requires_grad=True), Parameter containing:\n",
      "tensor([-3.5839, -3.7680, -3.2380, -2.6092, -4.2364, -1.0848, -3.2996, -4.6267,\n",
      "         0.1931,  0.5922, -2.2915, -2.4222, -3.7517, -2.8975, -1.9973,  0.4620,\n",
      "        -2.8584, -0.6654, -0.3538,  0.2815], requires_grad=True), Parameter containing:\n",
      "tensor([[-1.1666e-01,  1.9279e-02,  8.0801e-02,  1.9196e-01, -9.7504e-02,\n",
      "          2.1056e-01,  2.1495e-02, -1.2273e-01, -1.0769e-01,  1.1352e-01,\n",
      "          9.5345e-02, -1.6672e-01,  1.5637e-01, -1.3247e-01,  7.6810e-02,\n",
      "          1.9413e-01, -3.1924e-02,  1.2949e-01, -2.1333e-01, -1.7133e-01],\n",
      "        [-2.0185e-01,  2.8809e-01,  5.1332e-01,  1.9058e-01, -6.5446e-03,\n",
      "          3.2748e-01,  5.5917e-01,  6.8200e-01, -1.0120e-01,  9.8368e-02,\n",
      "          4.7639e-02,  3.3632e-01,  1.8736e-02,  1.5033e-01,  1.3428e-01,\n",
      "          1.0588e-02,  4.7648e-01, -8.2350e-02, -1.6630e-01, -2.2035e-01],\n",
      "        [ 7.1910e-02,  1.1117e-01, -1.1489e-01,  3.6159e-02,  4.9730e-01,\n",
      "         -2.0639e-01,  7.1280e-02, -4.5018e-02, -4.0111e-02,  3.1774e-01,\n",
      "          2.2055e-01, -2.4113e-01,  3.8628e-01,  1.3571e-01,  5.3098e-02,\n",
      "          1.3244e-01,  5.7419e-02,  1.9458e-01,  1.9823e-01, -3.4805e-02],\n",
      "        [ 2.8442e-02,  2.0362e-01, -1.8309e-02, -1.4990e-01, -2.1670e-01,\n",
      "          1.2610e-01,  3.1909e-02, -2.7248e-02, -1.9723e-01, -2.0675e-02,\n",
      "          1.4039e-01, -1.7840e-01,  2.1197e-01,  1.4663e-01,  1.3719e-01,\n",
      "         -1.5225e-01, -2.2230e-01, -3.1223e-02,  1.8343e-02, -1.8283e-01],\n",
      "        [ 1.3723e+00, -4.2993e-02,  1.7476e-01,  1.5276e+00,  1.9091e+00,\n",
      "         -1.5059e-02,  1.4828e-01, -3.5653e-03,  7.1144e-01,  9.8927e-02,\n",
      "          1.7881e-01,  5.0046e-02,  1.5718e+00, -1.9058e-01,  7.9637e-01,\n",
      "          7.3969e-01, -2.2157e-01, -3.2002e-02,  9.7508e-01,  7.8669e-01],\n",
      "        [-1.8774e+00,  1.0822e+00,  8.7761e-01, -4.5580e-01, -2.1292e+00,\n",
      "          1.8929e-01,  1.0667e+00,  1.6612e+00,  7.8142e-01, -3.5231e-01,\n",
      "          8.2149e-01,  8.7225e-01, -1.3769e+00,  8.2608e-01, -6.4292e-01,\n",
      "          9.7376e-01,  6.5054e-01, -4.6750e-02,  7.3561e-01,  8.5933e-01],\n",
      "        [ 2.1789e-01,  7.3615e-01,  7.3926e-01, -1.6607e-01,  1.5362e-01,\n",
      "          1.0158e-01,  9.6255e-01,  1.4701e+00,  9.2914e-02,  2.0016e-01,\n",
      "          4.1984e-01,  6.0070e-01, -1.0318e-01,  8.4576e-01, -1.0929e-01,\n",
      "          1.8052e-01,  6.5311e-01,  1.5427e-01, -1.2586e-01, -7.3722e-02],\n",
      "        [ 1.2401e-01,  4.3033e-02,  1.9919e-02,  5.0284e-02, -9.6294e-02,\n",
      "         -2.0819e-01,  2.4071e-02, -1.8602e-03, -2.0648e-01, -1.7624e-01,\n",
      "          1.2089e-01, -1.9778e-01, -1.1372e-01,  1.5231e-01, -2.2213e-02,\n",
      "         -1.7773e-01,  3.1073e-02,  1.3249e-01, -5.9717e-02,  1.3818e-01],\n",
      "        [-3.5104e-01,  4.8448e-01,  5.4223e-01,  1.9917e-01, -7.1151e-01,\n",
      "          2.9112e-01,  3.9161e-01,  5.3009e-01,  6.4996e-01, -7.2539e-02,\n",
      "          1.6187e-01,  7.8022e-01, -3.1112e-01,  3.7019e-01, -2.1947e-01,\n",
      "          2.4545e-01,  5.7651e-01, -1.2355e-01,  7.2542e-01,  6.3347e-01],\n",
      "        [-1.9240e-01,  2.6700e-01,  2.6172e-01, -9.2972e-02, -1.5843e-01,\n",
      "          3.1592e-01,  5.2037e-01,  5.8958e-01, -1.0573e-01,  1.7414e-01,\n",
      "          2.8082e-03,  3.3609e-01,  2.7182e-02,  4.4284e-01,  1.4117e-01,\n",
      "         -2.7254e-04,  7.3104e-02,  6.3942e-03, -2.5441e-02, -2.1004e-01]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.1250, -0.7130, -0.1084,  0.0161, -0.6973, -0.3219, -1.4758,  0.1112,\n",
      "        -0.0525, -0.2102], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.2245,  1.2429, -0.2939,  0.1967, -0.3755,  3.4299,  2.4828,  0.0229,\n",
      "          1.7154,  0.8847],\n",
      "        [-0.3054,  0.0587,  0.4806, -0.2163,  3.6460, -0.3319, -0.2391,  0.2418,\n",
      "          0.7753, -0.1548],\n",
      "        [-0.0145, -0.1903, -0.2616,  0.0816, -0.1427, -0.0312, -0.2779, -0.0556,\n",
      "         -0.2744, -0.0875],\n",
      "        [ 0.1913, -0.3045, -0.2634, -0.3129, -0.1654, -0.1737, -0.2198, -0.1768,\n",
      "         -0.1404, -0.2583],\n",
      "        [ 0.0652,  0.2563,  0.1564,  0.1511, -0.2228, -0.2159,  0.2050,  0.1802,\n",
      "         -0.1821,  0.0646]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0411,  0.3793,  0.2173, -0.1787, -0.1689], requires_grad=True), Parameter containing:\n",
      "tensor([[-4.5929,  3.7550, -0.0390, -0.0902,  0.1826]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0208], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "param_list = list(model.parameters())\n",
    "print(param_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Trained Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "win2=viz.scatter(\n",
    "    X = torch.cat([x, output],1),\n",
    "    opts=dict(\n",
    "        xtickmin=-10,\n",
    "        xtickmax=10,\n",
    "        xtickstep=1,\n",
    "        ytickmin=0,\n",
    "        ytickmax=500,\n",
    "        ytickstep=1,\n",
    "        markersymbol='dot',\n",
    "        markercolor=np.random.randint(0, 255, num_data),\n",
    "        markersize=5,\n",
    "    ),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Loss Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.reshape([i for i in range(num_epoch)],newshape=[num_epoch,1])\n",
    "loss_data = np.reshape(loss_arr,newshape=[num_epoch,1])\n",
    "\n",
    "win3=viz.line(\n",
    "    X = x,\n",
    "    Y = loss_data, \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
