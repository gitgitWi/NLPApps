{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network with Cubic Data (multi-dimensional)\n",
    "- y = x^3 -3x^2 -9x -1\n",
    "- 5 hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "from visdom import Visdom\n",
    "viz = Visdom()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/NLPApps/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/envs/NLPApps/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "num_data = 1000\n",
    "num_epoch = 5000\n",
    "\n",
    "x = init.uniform(torch.Tensor(num_data,1),-10,10)\n",
    "y = (x**3) - 3*(x**2) - 9*x - 1\n",
    "\n",
    "noise = init.normal(torch.FloatTensor(num_data,1),std=3)\n",
    "\n",
    "y_noise = y + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize data\n",
    "\n",
    "input_data = torch.cat([x,y_noise],1)\n",
    "\n",
    "win=viz.scatter(\n",
    "    X = input_data,\n",
    "    opts=dict(\n",
    "        xtickmin=-10,\n",
    "        xtickmax=10,\n",
    "        xtickstep=1,\n",
    "        ytickmin=0,\n",
    "        ytickmax=500,\n",
    "        ytickstep=1,\n",
    "        markersymbol='dot',\n",
    "        markercolor=np.random.randint(0, 255, num_data),\n",
    "        markersize=5,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize data\n",
    "\n",
    "input_data = torch.cat([x,y_noise],1)\n",
    "\n",
    "win=viz.scatter(\n",
    "    X = torch.cat([x,y],1),\n",
    "    opts=dict(\n",
    "        xtickmin=-10,\n",
    "        xtickmax=10,\n",
    "        xtickstep=1,\n",
    "        ytickmin=0,\n",
    "        ytickmax=500,\n",
    "        ytickstep=1,\n",
    "        markersymbol='dot',\n",
    "        markercolor=np.random.randint(0, 255, num_data),\n",
    "        markersize=5,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully connected model with 5 hidden layer\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(1,20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20,10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10,5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5,1),\n",
    "        )\n",
    "\n",
    "loss_func = nn.L1Loss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(207.6893, grad_fn=<L1LossBackward>)\n",
      "tensor(207.5146, grad_fn=<L1LossBackward>)\n",
      "tensor(207.3026, grad_fn=<L1LossBackward>)\n",
      "tensor(206.9702, grad_fn=<L1LossBackward>)\n",
      "tensor(206.3380, grad_fn=<L1LossBackward>)\n",
      "tensor(205.1090, grad_fn=<L1LossBackward>)\n",
      "tensor(202.1986, grad_fn=<L1LossBackward>)\n",
      "tensor(193.3711, grad_fn=<L1LossBackward>)\n",
      "tensor(162.9212, grad_fn=<L1LossBackward>)\n",
      "tensor(140.9089, grad_fn=<L1LossBackward>)\n",
      "tensor(139.3763, grad_fn=<L1LossBackward>)\n",
      "tensor(138.3421, grad_fn=<L1LossBackward>)\n",
      "tensor(137.2979, grad_fn=<L1LossBackward>)\n",
      "tensor(136.2049, grad_fn=<L1LossBackward>)\n",
      "tensor(135.0326, grad_fn=<L1LossBackward>)\n",
      "tensor(133.7457, grad_fn=<L1LossBackward>)\n",
      "tensor(132.3647, grad_fn=<L1LossBackward>)\n",
      "tensor(130.8322, grad_fn=<L1LossBackward>)\n",
      "tensor(129.0903, grad_fn=<L1LossBackward>)\n",
      "tensor(127.0562, grad_fn=<L1LossBackward>)\n",
      "tensor(124.6493, grad_fn=<L1LossBackward>)\n",
      "tensor(121.7518, grad_fn=<L1LossBackward>)\n",
      "tensor(118.1299, grad_fn=<L1LossBackward>)\n",
      "tensor(113.4113, grad_fn=<L1LossBackward>)\n",
      "tensor(107.1555, grad_fn=<L1LossBackward>)\n",
      "tensor(99.1869, grad_fn=<L1LossBackward>)\n",
      "tensor(91.2291, grad_fn=<L1LossBackward>)\n",
      "tensor(84.7388, grad_fn=<L1LossBackward>)\n",
      "tensor(78.9432, grad_fn=<L1LossBackward>)\n",
      "tensor(74.5255, grad_fn=<L1LossBackward>)\n",
      "tensor(72.2126, grad_fn=<L1LossBackward>)\n",
      "tensor(84.6262, grad_fn=<L1LossBackward>)\n",
      "tensor(82.8999, grad_fn=<L1LossBackward>)\n",
      "tensor(83.1962, grad_fn=<L1LossBackward>)\n",
      "tensor(75.3164, grad_fn=<L1LossBackward>)\n",
      "tensor(75.5084, grad_fn=<L1LossBackward>)\n",
      "tensor(75.6249, grad_fn=<L1LossBackward>)\n",
      "tensor(74.8919, grad_fn=<L1LossBackward>)\n",
      "tensor(81.3783, grad_fn=<L1LossBackward>)\n",
      "tensor(80.5110, grad_fn=<L1LossBackward>)\n",
      "tensor(80.3021, grad_fn=<L1LossBackward>)\n",
      "tensor(79.9322, grad_fn=<L1LossBackward>)\n",
      "tensor(79.9388, grad_fn=<L1LossBackward>)\n",
      "tensor(79.6520, grad_fn=<L1LossBackward>)\n",
      "tensor(79.2405, grad_fn=<L1LossBackward>)\n",
      "tensor(78.9822, grad_fn=<L1LossBackward>)\n",
      "tensor(78.6675, grad_fn=<L1LossBackward>)\n",
      "tensor(78.1855, grad_fn=<L1LossBackward>)\n",
      "tensor(77.6436, grad_fn=<L1LossBackward>)\n",
      "tensor(77.5061, grad_fn=<L1LossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss_arr =[]\n",
    "label = y_noise\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    output = model(x)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = loss_func(output,label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 100 ==0:\n",
    "        print(loss)\n",
    "        \n",
    "    #loss_arr.append(loss.cpu().data.numpy()[0])\n",
    "    loss_arr.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.1574],\n",
      "        [ 0.4888],\n",
      "        [-0.9629],\n",
      "        [ 0.0706],\n",
      "        [ 0.8396],\n",
      "        [-0.2532],\n",
      "        [-0.2026],\n",
      "        [-0.0622],\n",
      "        [-0.3793],\n",
      "        [-0.5672],\n",
      "        [ 0.4430],\n",
      "        [-0.6391],\n",
      "        [ 0.8653],\n",
      "        [-0.4822],\n",
      "        [-0.4649],\n",
      "        [-0.3214],\n",
      "        [-0.0952],\n",
      "        [ 0.5226],\n",
      "        [-0.9457],\n",
      "        [-0.5726]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.6232, -1.2895, -1.6850, -0.8309, -0.2228,  0.8806, -1.0909, -0.3971,\n",
      "        -0.4991, -3.0722, -1.1998, -2.6425,  1.0104, -1.1385, -2.8779, -1.2731,\n",
      "        -0.9485, -0.5809, -1.1077, -3.1012], requires_grad=True), Parameter containing:\n",
      "tensor([[-8.0886e-02, -8.7825e-02, -6.4715e-02,  5.4652e-02, -1.6143e-01,\n",
      "          2.6163e-01,  8.8158e-02,  2.6488e-03,  4.0503e-02, -3.3668e-01,\n",
      "          1.5316e-01,  3.7321e-02,  7.8760e-02, -8.9424e-02, -2.3068e-01,\n",
      "         -1.8225e-01, -6.7596e-02, -1.6399e-01,  1.5160e-01, -7.3753e-02],\n",
      "        [-2.7923e-02, -8.6244e-02,  3.2437e-01,  2.3071e-02, -1.0078e-01,\n",
      "          1.8208e-01,  3.2292e-01,  1.9783e-01,  9.6404e-02,  6.1035e-01,\n",
      "          9.6242e-02,  5.4421e-01, -5.8124e-02,  3.3709e-01,  8.5667e-01,\n",
      "          3.0565e-01,  3.5948e-02, -3.3634e-03,  5.2506e-01,  5.5271e-01],\n",
      "        [-1.4974e-01, -1.4708e-01,  5.8438e-02,  1.2344e-01,  5.6408e-03,\n",
      "          1.4922e-01,  2.9664e-02,  1.2282e-01, -8.6305e-02,  1.7766e-01,\n",
      "         -2.0328e-01, -8.9736e-02, -7.9114e-02,  1.5272e-01,  3.6953e-02,\n",
      "          1.1760e-01, -7.5118e-02, -1.4719e-01, -2.6523e-01,  7.6779e-02],\n",
      "        [ 3.4763e-01, -4.9858e-02,  7.9875e-01,  1.8024e-01,  2.7764e-02,\n",
      "         -3.2563e-01,  5.9074e-01,  2.9202e-01,  1.7437e-01,  1.8071e+00,\n",
      "         -2.2198e-01,  1.4905e+00, -1.4816e-01,  5.9463e-01,  1.6508e+00,\n",
      "          4.7487e-01, -1.6240e-01, -5.4193e-02,  4.1482e-01,  1.7719e+00],\n",
      "        [-7.8248e-02,  1.4364e-01, -3.4829e-02, -1.6558e-02, -1.0272e-01,\n",
      "         -6.0382e-02, -7.8478e-02, -1.4633e-01,  2.0215e-01, -1.2844e-01,\n",
      "         -5.6554e-02,  7.8543e-02, -1.3801e-01,  1.2618e-01, -8.2729e-02,\n",
      "         -8.7610e-02,  1.0035e-01,  1.2527e-01, -9.0645e-02, -1.4964e-01],\n",
      "        [ 3.9870e-03,  9.0614e-02,  3.6395e-02, -5.2129e-02, -2.1716e-01,\n",
      "         -1.9752e-01, -2.0577e-02,  8.1342e-03, -3.3364e-02, -2.1858e-03,\n",
      "         -2.8529e-01,  1.8431e-01,  2.0004e-01,  4.3311e-02, -8.4847e-02,\n",
      "         -1.4959e-01, -2.1829e-01, -2.1187e-02, -1.8493e-01,  7.0366e-02],\n",
      "        [ 1.9068e-01, -2.8619e-01,  3.2141e-02,  9.5142e-02, -3.9390e-02,\n",
      "          9.3086e-02, -1.8027e-01, -1.2931e-01, -6.7386e-03, -1.9356e-01,\n",
      "         -1.0717e-01,  5.0501e-02,  9.3154e-02, -2.3737e-01, -1.6598e-01,\n",
      "          1.9872e-01, -3.2506e-03,  1.8685e-02, -7.6184e-02, -1.2254e-01],\n",
      "        [-4.7820e-03,  2.8183e-01,  1.2007e-01,  1.4597e-01,  3.8819e-01,\n",
      "         -1.4345e-01, -1.9802e-01,  2.1599e-01, -1.1445e-03,  1.5586e-01,\n",
      "          2.7378e-01, -1.2427e-01,  3.7962e-01, -2.8978e-02, -1.7089e-01,\n",
      "         -2.0408e-01,  9.3116e-02,  3.7428e-01, -7.1853e-02, -5.1147e-02],\n",
      "        [ 2.7421e-01, -9.3894e-01,  7.1958e-01, -5.5173e-02, -5.5365e-02,\n",
      "         -4.5260e-01,  3.9609e-01,  1.3447e-01,  3.3550e-01,  1.2765e+00,\n",
      "         -9.9862e-01,  8.1501e-01,  7.4863e-01,  2.5174e-01,  1.2685e+00,\n",
      "          6.2946e-01, -1.6845e-01, -4.4300e-01,  6.9819e-01,  1.4062e+00],\n",
      "        [ 8.0506e-02,  6.7748e-02, -1.5397e-01, -1.6577e-01, -2.2064e-01,\n",
      "          2.4654e-01,  5.8931e-02,  1.5732e-01,  2.0027e-01, -2.1102e-01,\n",
      "          3.7055e-02,  3.1647e-02,  1.7003e-02,  4.2061e-02, -2.7311e-01,\n",
      "         -1.8773e-03, -3.5923e-03,  4.7026e-02,  8.1380e-02, -2.8064e-01]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.2167, -0.5137, -0.2285, -1.6774, -0.0085,  0.2343,  0.1553,  0.0806,\n",
      "        -0.0899,  0.3501], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.2658,  0.7006, -0.2190,  0.9983,  0.1484,  0.2977, -0.0856, -0.1994,\n",
      "          1.0974, -0.1851],\n",
      "        [-0.2945,  0.4485, -0.2588,  1.5154, -0.1102,  0.3594,  0.1649, -0.0502,\n",
      "          0.9872, -0.0725],\n",
      "        [-0.2662,  0.1978, -0.3139, -0.2280,  0.1397, -0.2906,  0.1510,  0.7362,\n",
      "         -0.1818,  0.1122],\n",
      "        [-0.3438,  1.3393, -0.2036,  3.4394,  0.3089,  0.0684,  0.3538, -0.0845,\n",
      "          2.7525, -0.5124],\n",
      "        [ 0.2191,  0.2339, -0.2559, -0.0715, -0.1596, -0.0706, -0.2626,  0.4194,\n",
      "         -0.1864,  0.1201]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.2129, -0.0329,  0.4116, -0.0680,  0.2350], requires_grad=True), Parameter containing:\n",
      "tensor([[-1.6501, -1.8659,  0.7646, -4.6281,  0.5107]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0230], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "param_list = list(model.parameters())\n",
    "print(param_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Trained Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "win2=viz.scatter(\n",
    "    X = torch.cat([x, output],1),\n",
    "    opts=dict(\n",
    "        xtickmin=-10,\n",
    "        xtickmax=10,\n",
    "        xtickstep=1,\n",
    "        ytickmin=0,\n",
    "        ytickmax=500,\n",
    "        ytickstep=1,\n",
    "        markersymbol='dot',\n",
    "        markercolor=np.random.randint(0, 255, num_data),\n",
    "        markersize=5,\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Loss Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.reshape([i for i in range(num_epoch)],newshape=[num_epoch,1])\n",
    "loss_data = np.reshape(loss_arr,newshape=[num_epoch,1])\n",
    "\n",
    "win3=viz.line(\n",
    "    X = x,\n",
    "    Y = loss_data, \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
